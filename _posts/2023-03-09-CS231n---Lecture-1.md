---
layout: single
date: 2023-03-09
title: "CS231n - Lecture 1"
use_math: true
tags: [강의/책 정리, ]
categories: [AI, ]
---


## **Lecture 1. Introduction to Convolutional Neural Networks for Visual Recognition**



### Why Computer Vision?

- CISCO에서 발표한 통계에 따르면 2015 ~ 2017년도까지 **인터넷 트래픽 중 80%가 영상 데이터**이다. 이는 **인터넷 데이터 대부분이 시각 데이터**라는 사실을 알 수 있다.
- 따라서 이러한 시각 데이터를 잘 활용할 수 있는 알고리즘을 개발하는 노력이 필요하다. 하지만 시각 데이터는 암흑 물질(Dark Matter)라고 불릴 정도로 해석하기 굉장히 까다롭다.
- Youtube의 통계에 따르면 매초 5시간 분량의 비디오가 업로드된다고 한다.
- Computer Vision 알고리즘을 구현할 때 `물리학`**,** `생물학`**,** `심리학`**,** `컴퓨터과학`**,** `수학`**,** `공학`의 개념을 모두 활용하여 우리 눈에 보이는 사물들을 기하학적으로 재구


### History of Vision



#### Biological Vision (Evolution’s Big Bang)

- 5억 4천만년 전에 천만 년이라는 짧은 시간동안 생물의 종이 폭발적으로 증가한 시기가 있었다.
- Andrew Parker의 가설은 `Biological Vision`의 탄생이다.
- 5억 4천만년 전 최초의 눈(eyes)이 생기고, **대뇌 피질의 50% 가량의 뉴런을 시각 처리에 관여**할만큼 가장 중요한 감각기관으로 자리매김했다.


#### Mechanical Vision (Camera)


![0](/assets/img/2023-03-09-CS231n---Lecture-1.md/0.png)

- 1600년대 르네상스 시대의 카메라, Obscura
	- 핀홀 카메라 이론을 기반으로 함 - 빛을 모아주는 구멍 1개, 뒤편의 평평한 면에서 정보를 모으고 이미지를 투영
	- 생물학적으로 발전한 초기의 눈과 상당히 유사


#### Hubel & Wiesel’s electrophysiology (1959)

- “What was the visual processing mechanism like in primate, in mammals”
- 시각 처리 매커니즘이 인간의 뇌와 비슷한 고양이 뇌를 연구
	- 고양이 두뇌 뒷면(primary visual cortex area)에 전극을 꽂아 어떤 자극에 격렬하게 반응하는지 관찰
- 시각 처리가 처음에는 단순한 구조로 시작되며 실제 세상을 인지할 때까지 통로를 거치면서 점점 복잡해진다.


### History of Computer Vision



#### Block World (Larry Roberts, 1963)


![1](/assets/img/2023-03-09-CS231n---Lecture-1.md/1.png)

- 컴퓨터 비전은 60년대 초반에 태동했다
- 컴퓨터 비전 분야에서 **최초의 박사 학위 논문**으로, 우리 눈에 보이는 사물들을 기하학적 모양으로 단순화했다.
- 이 연구의 목표는 우리 눈에 보이는 세상을 인식하고 재구성하는 것이다.


#### “The Summer Vision Project” (1966)

- “The summer vision project is an attempt to use out summer workers effectively in the construction of a significant part of a visual system.”
- 시각 시스템 전반을 구현하기 위한 프로젝트이며, 대부분의 시각 체계를 구현하려는 시도이다
- 이때부터 시작해 50년이 지난 지금까지도 여전히 수 천명의 연구자들이 비전을 연구하고 있다


#### Vision - David Marr (1970s)


![2](/assets/img/2023-03-09-CS231n---Lecture-1.md/2.png)

- David Marr가 비전을 무엇이라 생각하는지, 컴퓨터 비전이 어떤 방향으로 나아가야 하는지, 컴퓨터 비전을 인식하기 위해 어떤 방향으로 알고리즘을 개발해야 하는지를 다룬 책이다.
- 우리가 눈으로 받아들인 **‘Image’**를 최종적인 **‘Full 3D Model Representation’**으로 만들기 위한 몇 단계 과정을 소개한다.
	1. **Input Image**
	2. **Primal Sketch**

		`Edges, Bars, Ends, Virtual Lines, Curves, Boundaries`가 표현되는 과정


		Hubel & Wiesel은 시각 처리 초기 단계는 경계와 같은 단순한 구조와 아주 밀접한 관계가 있다고 했다

	3. **2.5D Sketch**

		시각 장면을 구성하는 `Surfaces, Depth, Layers, Discontinuities`를 종합한다

	4. **3D Model Representation**

		모든 것을 한데 모아서 `Surface and Volumetric Primitives` 형태의 계층적으로 조직화된 최종적인 3D 모델을 만든다

- 이런 사고 방식은 시각 정보를 분석하는데 직관적인 사고 방식이고, 오랫동안 비전에 대한 아주 인상적이고 지배적인 사고 방식이다


#### Generalized Cylinder (Brooks & Binford, 1979) & Pictorial Structure (Fischler & Elschlager, 1973)

- PC가 보급되기도 전에 컴퓨터 과학자들은 어떻게 대상을 인식하고 표현할 수 있을지 고민했다.
- “모든 객체는 단순한 모양과 기하학적인 구성로 표현할 수 있다”는 개념으로 접근했다
- **Generalized Cylinder** : 사람을 원통 모양으로 조합해서 표현
- **Generalized Cylinder** : 사람을 원통 모양으로 조합해서 표현
- **Pictorial Structure** : 사람을 주요 부위와 관절로 표현

![3](/assets/img/2023-03-09-CS231n---Lecture-1.md/3.png)


![4](/assets/img/2023-03-09-CS231n---Lecture-1.md/4.png)


![5](/assets/img/2023-03-09-CS231n---Lecture-1.md/5.png)



#### David Lowe (1987)


![6](/assets/img/2023-03-09-CS231n---Lecture-1.md/6.png)

- 어떻게 실제 세계를 단순한 구조로 재구성/인식할 수 있을지 고민했다
- `Lines, Edges, Straight Lines`의 조합을 이용해서 사물을 재구성
- 60~80년대는 컴퓨터 비전으로 어떤 일을 할 수 있을지 고민한 시기이지 단순한 Toy Example에 불과했다


#### Object Segmentation - Normalized Cut (Shi & Malik, 1997)


![7](/assets/img/2023-03-09-CS231n---Lecture-1.md/7.png)

- 영상 분할(Image Segmentation)은 이미지의 각 픽셀을 의미있는 방향으로 군집화하는 방법
- 영상 분할 문제를 해결하기 위해 그래프 이론을 도입했다


#### Object Recognition - SIFT (David Lowe, 1999)


![8](/assets/img/2023-03-09-CS231n---Lecture-1.md/8.png)

- 1990년대 후반부터 2010년도까지 ‘Feature Based Object Recognition’ 알고리즘이 주였다
	- 카메라 앵글, 빛, 화각 등의 문제로 같은 객체도 변할 수 있다
	- David Lowe의 **‘SIFT Feature’**는 전체 객체의 특징 중 일부는 다양한 변화에 조금 더 강인하고 불변하다는 점을 발견했다
	- **객체에서 중요한 특징을 찾아내고, 다른 객체에 그 특징들을 매칭**시키는 방법이다
- 이미지에 존재하는 `‘Feature’`를 사용하면서 컴퓨터 비전은 또 한 번의 도약을 할 수 었다.


#### Face Detection (Viola & Jones, 2001)

- 컴퓨터 비전에서 유난히 발전 속도가 빨랐던 분야가 얼굴 인식이다
- 이 연구를 시작으로 ‘Statistical Machine Learning Technique’가 탄력을 받기 시작 - Support Vector Machine, Boosting, Graphical Models, Neural Network
- Paul Viola & Michael Jones가 AdaBoost 알고리즘을 이용해 Real-Time Face Detection에 성공했다
- 5년이 지난 2006년 Fuji Film에서 Real-Time Face Detection이 가능한 디지털 카메라를 최초로 발표


#### Support Vector Machine - Spatial Pyramid Matching (Lazebnik, Schimid & Ponce, 2006)

- 기본 아이디어는 이미지에서 특징을 잘 뽑아내면, 특징들이 이미지에 대한 단서를 제공해줄 것이라는 생각
- 이미지의 여러 부분과 여러 해상도에서 추출한 특징을 하나의 feature descriptor로 표현하고 Support Vector Machine 알고리즘을 적용함


#### Human Recognition - Hog (Dalal & Triggs, 2005) & Deformable Part Model (McAllester & Ramanan, 2009)

- 사람의 몸을 어떻게 현실적으로 모델링할 수 있을지에 관련한 연구이다


#### PASCAL Visual Object Challenge ( 2006 ~ 2012)


![9](/assets/img/2023-03-09-CS231n---Lecture-1.md/9.png)

- 인터넷과 디지털 카메라의 발전으로 더욱 좋은 실험 데이터를 만들어 낼 수 있었다
- 2000년대 초에 컴퓨터 비전이 앞으로 풀어야 할 문제가 무엇인지의 정의를 어느정도 내리게 되었다. 그 중 하나가 ‘Object Recognition’이다.
- ‘Object Recognition’ 기술이 어디쯤 왔는지 측정해 보기 위해서 Benchmark Dataset을 모으기 시작했다. 그 중 하나가 **‘PASCAL Visual Object Challenge(VOC)’**이다.
- 20개의 클래스가 있고, 클래스 당 수천 수만 개의 이미지들이 있다.
- 연구자들은 자신들의 알고리즘을 테스트했고, ‘Object Recognition’ 성능은 꾸준히 증가했다.


#### ImageNet Large Scale Visual Recognition Challenge (ILSVRC)


![10](/assets/img/2023-03-09-CS231n---Lecture-1.md/10.png)

- Graphical Model, SVM, AdaBoost와 같이 대부분의 머신러닝 알고리즘에서 Overfitting 문제가 발생

	→ 시각 데이터가 너무 복잡하다


	→ Input은 복잡한 고차원 데이터이고, 이 모델을 fit하려면 더 많은 Parameter가 필요하다


	→ 학습 데이터가 부족하면 Overfitting이 훨씬 더 빠르게 발생했고, 일반화 능력이 떨어졌다.

- 머신러닝 알고리즘의 ‘Overfitting’문제를 극복하고, 세상의 모든 객체들을 인식하기 위해서 ImageNet 프로젝트가 시작되었다
- ImageNet 데이터는 **22만 가지의 클래스와 15만 장의 이미지**를 보유하게 되었다.
- 이미지 분류 문제를 푸는 알고리즘을 테스트하기 위해 2009년부터 ILSVRC 대회를 개최했다 (1000개의 클래스, 140만 개의 이미지)
- 2012년 챌린지에서 우승한 알고리즘이 바로 **Convolutional Neural Network(Deep Learning)**
	- CNN이 바로 컴퓨터 비전의 비약적인 발전을 이끌어낸 주역

	![11](/assets/img/2023-03-09-CS231n---Lecture-1.md/11.png)



### Concept of Object Recognition

- Image Classification : 이미지를 보고 몇 개의 고정된 카테고리 안에서 정답을 고른다
- Object Detection : 이미지에서 객체를 분류하고, 객체의 영역이 어디인지 박스를 그린
- Image Captioning : 이미지를 보고 묘사할 수 있어야 한다


### Convolutional Neural Networks (CNN)



#### 2012년 이전의 CNN - LeNet


![12](/assets/img/2023-03-09-CS231n---Lecture-1.md/12.png)

- 1998년 숫자 인식을 위해 CNN을 구축했다
- 이미지를 받아 숫자와 문자를 인식할 수 있도록 하여, 자필 수표 자동 판독과 우편 주소 자동인식에 활용햇다
- Raw Pixel을 받아 여러 Convolution Layer을 거치고 Sub-Sampling, Fully-Connected Layer을 거치게 된다
- Lenet의 아키텍처와 2012년의 AlexNet의 아키텍처는 유사하다


#### 2012년 이후의 CNN


![13](/assets/img/2023-03-09-CS231n---Lecture-1.md/13.png)

- 2012년이 되어서야 CNN이 빛을 보게 된 이유는 바로 (1)**연산량의 증가**와 (2)**데이터의 증가** 때문임
	1. **연산량의 증가**
		- 연산량의 증가는 딥러닝 역사에서 아주 중요한 요소임
		- 컴퓨터의 계산속도가 매년 빨라져서 계산 능력이 좋아짐 (**무어의 법칙**)
		- GPU의 발전으로 강력한 병렬처리가 가능해짐, 이는 계산 집약적인 CNN 모델을 고속으로 처리하는데 적합함
	2. **데이터의 증가**
		- 90년대와 비교했을 때 사용 가능한 데이터셋이 매우 많아짐


### Open Challenges

- Semantic Segmentation (Perceptual Grouping)

	→ 이미지의 모든 픽셀을 이해하는 분야

- Activity Recognition

	→ Augmented Reality, Virtual Reality 분야에서 활용

- Object Relationships
- Understand story of image


### The Goal of Computer Vision

- 사람처럼 볼 수 있는 Machine을 만들자
- Semantic Segmentation, Perceptual Grouping, 3D understanding, Action Recognition
