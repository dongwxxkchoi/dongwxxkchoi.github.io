---
layout: single
date: 2023-03-14
title: "CS231n - Lecture 2"
use_math: true
author_profile: false
tags: [강의/책 정리, ]
categories: [AI, ]
---


## Lecture 2. Image Classification Pipeline



### Image Classification

- Image Classification은 이미지를 입력받아 이를 분류하는 것을 말한다
- 사람에게는 이미지 분류가 쉬워 보이지만 컴퓨터에게는 그저 숫자의 집합이라서 어려운 작업이다
- 이미지의 ‘Feature’를 찾고, ‘Feature’을 이용하여 명시적인 규칙을 만들어서 접근하면 다양한 이미지에 적용하기 어렵다

	![0](/assets/img/2023-03-14-CS231n---Lecture-2.md/0.png)


	
{% raw %}
```python
	def classify_image(image):
		# Some magic here?
		return class_label  --> Dog, Cat, Truck, Plane etc
```
{% endraw %}


- 또한 이미지는 **Viewpoint Variation, Illumination, Deformation, Occlusion, Background Clutter, Intraclass Variation**과 같은 작은 변화에 숫자 값들은 민감하게 반응한다
- 우리는 **이러한 다양한 상황을 이겨낼 수 있는 "확장성"을 가진 이미지 분류 알고리즘**을 찾아야한다.
- 우리는 이러한 것을 해결하는 방법으로 **"Data-Driven Approach"**을 소개한다


### Data-Driven Approach

- 단순히 사진 1장만을 가지고 결정을 하는 것이 아니라 **무수히 많은 사진들과 그 사진에 대한 정보** 를 이용하여 **이미지 분류기를 만들고** 새로운 사진에 대해 분류하는 접근방식을 말한다.
	1. **데이터 셋 (Dataset)**

		무수히 많은 **데이터** 뿐 아니라 각 데이터에 대한 정보를 나타내는 **라벨(Label)** 이 함께 달린 데이터를 말한다

	2. **데이터 학습 (Train)**

		새로운 이미지를 판단하기 위해 데이터 셋을 이용하여 미리 **분류기를 만들고 학습하는 과정**을 말한다


		
{% raw %}
```python
		def train(images, labels):
			# Machine Learning!
			return model
```
{% endraw %}


	3. **데이터 판단 (Predict)**

		학습된 분류기를 이용하여 **새로운 이미지**에 대해 **판단, 분류 및 예측**을 하는 과정을 말한다


		
{% raw %}
```python
		def predict(model, test_images):
			# Use model to predict Labels!
			return test_labels
```
{% endraw %}




### Nearest Neighbor



{% raw %}
```python
import numpy as np

class NearestNeighbor:
	def __init__(self):
		pass

	def train(self, X, y):
		""" X is N x D where each row is an example. Y is 1-dimesion of size N """
		self.Xtr = X
		self.ytr = y

	def predict(self, X):
		""" X is N x D where each row is an example we wish to predict label for """
		num_test = X.shape[0]
		# lets make sure that output type matches the input type
		Ypred = np.zeros(num_test, dtype = self.ytr.dtype)

		# loop over all test rows
		for i in xrange(num_test):
			# find the nearest training image to the i'th test image
			# using the L1 distance (sum of absolute value differences)
			distances = np.sum(np.abs(self.xtr = X[i,:]), axis = 1)
			min_index = np.argmin(distances) # get the index with smallest distance
			Ypred[i] = self.ytr[min_index] # predict the label of the nearest example

		return Ypred
```
{% endraw %}


- **새로운 이미지**와 **이미 알고 있던 이미지** 를 비교하여 **가장 비슷하게 생긴 것을 찾아 내는 것**을 말한다.
	1. **데이터 학습(Train)**

		나중에 새로운 이미지와의 비교를 위해 **단순히 Train 이미지를 저장**한다. `O(1)`

	2. **데이터 판단(Predict)**

		Input 이미지로 Train 이미지와 **가장 비슷한 이웃을 찾고 그에 따라 분류**한다. `O(N)`

- 문제점
	- **데이터 학습은 빠르지만, 새로운 데이터를 판단하는데 있어서 걸리는 시간이 많이 필요합니다.**
	- 단순히 픽셀값을 비교하는 것으로는 오류가 발생하기 쉽다.


### K-Nearest Neighbors


![1](/assets/img/2023-03-14-CS231n---Lecture-2.md/1.png)

- **가까운 이웃을 K**개 만큼 찾고, **이웃끼리 투표**를 하는 방법이다
- Test Data와 Train Data 사이의 거리가 가장 짧은 K개의 Train Data를 고르고, 그 중 다수의 Class로 결정된다
- K 값이 증가함에 따라서 **경계가 점점 부드러워 지고 있는 것을 볼 수 있고,** 이러한 방식을 이용하면 좀 더 일반화 된 **결정 경계**를 찾을 수 있다.
- K 값이 증가함에 따라 결정 경계가 부드러워 지지만, 어느 쪽에도 분류할 수 없는 **흰색 영역이 증가** 하는 것을 볼 수 있다.
- 이러한 부분에서 **K값이 증가한다고 항상 좋은 것이 아니라. 데이터나 상황에 따라서 알맞은 K값을 찾아야한다.**


### Distance Matrix

- 데이터 간에 거리를 측정하는 방법으로 크게 L1과 L2 방식으로 나누어진다.
- L1은 각 성분의 차이를 모두 더한 값이고, L2는 유클리드 거리를 사용한다

$$
L_1(Manhattan) \ Distance : \\ d_1(I_1, I_2)=\sum\vert I_1^p-I_2^p \vert
$$


$$
L_1(Manhattan) \ Distance : \\ d_1(I_1, I_2)=\sum\vert I_1^p-I_2^p \vert
$$


$$
L_2(Euclidean) \ Distance : \\ d_2(I_1, I_2)=\sqrt{ \sum ( I_1^p-I_2^p )^2}
$$


![2](/assets/img/2023-03-14-CS231n---Lecture-2.md/2.png)


![3](/assets/img/2023-03-14-CS231n---Lecture-2.md/3.png)


![4](/assets/img/2023-03-14-CS231n---Lecture-2.md/4.png)


![5](/assets/img/2023-03-14-CS231n---Lecture-2.md/5.png)


![6](/assets/img/2023-03-14-CS231n---Lecture-2.md/6.png)


![7](/assets/img/2023-03-14-CS231n---Lecture-2.md/7.png)

- **L1의 특징**
	- 기존의 좌표계를 **회전하면 거리가 바뀐다**
	- **각 성분이 개별적인 의미**를 가지고 있을 때 L1이 더 적합하다
	- 중요한 Feature를 알 수 있을 때?
	- Ex) 키, 몸무게
- **L2의 특징**
	- L1과 다르게 기존의 좌표계를 회전해도 거리가 변하지 않는다
	- 일반적인 벡터이며, 요소들간의 실질적인 의미가 없는 경우에 L2가 더 적합하다
- **L1과 L2의 결정**
	- 사실적으로 데이터의 성분 관계를 정확하게 알지 못하는 경우가 대부분이라, 이를 정하는 것은 깊게 생각하지 말고, **둘 다 사용해보고 성능이 더 좋은 것을 사용한다**
	- 종속 변수 값을 예측하는 데에 어떤 변수가 중요한지 알면 L1, 모르면 L2를 사용한다

		→ L1은 주요하지 않은 변수값을 0으로 처리할 수 있기 때문

	- 요소들 간의 실질적인 의미를 잘 모르는 경우라면 L2가 더 나을 수 있


### Hyperparameter

- KNN에서 `K, Distance Matrix`와 같이 **우리가 직접 정해 주어야 하는 값**들을 Hyperparameter라고 한다
- 이러한 **Hyperparameter의 값은 상황에 따라서 다른 값을 가지므로** 이를 찾아가는 과정이 필요하다


#### Hyperparameter 설정 방법

- Idea #1: 모든 데이터를 **Train** 으로 사용하는 방법
	- 우리는 주어진 데이터에서 좋은 성능을 가지는 것보다 **새로운 데이터 들에 대해 높은 정확도** 를 가져야 한다.
	- 모든 데이터를 사용하는 경우 KNN에서 K=1인 경우 Train set에 대해 가장 좋은 결과를 가지지만, 새로운 데이터에 대해서는 그렇지 않다

	![8](/assets/img/2023-03-14-CS231n---Lecture-2.md/8.png)

- Idea #2: 데이터를 **Train과 Test** 로 나누는 방법
	- Train 데이터를 이용해서 Test 데이터가 정답인지 아닌지 확인하고, K값을 바꾸어 가면서 이중에 가장 높은 성능을 가지는 K값을 찾는다
	- 하지만 이 방법은 **이 Test 데이터에 대해서만 좋은 결과 값을 가질 수**도 있다
	- 우리는 **실제로 보지 않은 데이터에 대해서 좋은 성능을 평가**해야 한다.

	![9](/assets/img/2023-03-14-CS231n---Lecture-2.md/9.png)

- Idea #3: 데이터를 **Train, Validation(Dev), Test** 로 나누는 방법
	- **Train를 한 뒤에 Validation을 이용하여 좋은 성능을 가지는 Hyperparameter를 찾은 뒤** 에 **마지막에 딱 한번 Test 데이터를 테스트**하여, 이 데이터를 최대한 **"Unseen Data"로 활용하는 방법이다**
	- 위 방법들 중 **이 방법이 제일 올바른 방법이다**

	![10](/assets/img/2023-03-14-CS231n---Lecture-2.md/10.png)

- Idea #4 : **Crose-Validation**
	- **Dataset를 Fold 단위로 자르고**, 이 **Fold 중 하나를 Validation으로 선택하고 나머지를 Train 데이터로 사용**한다
	- **Validation으로 사용할 Fold를 바꿔가면서 반복**하고, 이 중 **가장 좋은 성능을 가지는 Hyperparameter를 찾아내는 방법**이다
	- 이 방법은 **Validation 데이터가 편향되는 현상**을 방지할 수 있다
	- 기존에 방식보다 **많은 학습시간** 을 요구하며 **이 방법은 거의 사용되지 않고** **데이터가 적은 상황에서 유용한 장점**을 가진다

	![11](/assets/img/2023-03-14-CS231n---Lecture-2.md/11.png)



#### Hyperparameter 예시


![12](/assets/img/2023-03-14-CS231n---Lecture-2.md/12.png)

- 5-fold cross-validation를 이용하여 **학습한 결과**이다. `가로축은 K값`을, `세로축은 성능`을 나타내고, 성능은 `K = 7`일때 가장 좋은 성능을 보이는 것을 볼 수 있다. 하지만 이것이 **항상 K가 7일때 좋은 결과를 가진다는 것**이 아니라 `데이터셋의 종류, 찾는 문제`에 따라서 **달라진다**


### NN & KNN이 Image Classification에 절대 쓰이지 않는 이유 



#### Test 시간이 오래 걸림

- 우선 초반에 언급했듯이 Predict(Test) 과정이 오래 걸린다.


#### 이미지의 Distance 의미

- 우선 초반에 언급했듯이 **Predict 과정이 오래 걸리고,** **사진 간에 distance 값이 이미지에서 그렇게 의미있는 값이 아니다**
- 가장 왼쪽에 원본 이미지와 변형된 3개의 이미지가 있는데, 여기서 재밌는 부분은 **원본사진과 각각의 사진에 거리가 모두 같은 사진**이다
- 이러한 관점에서 이미지의 Distance의 값은 그렇게 의미 있는 값이 아닙니다.
- 얼핏보면 같다고 판단하면 좋아보이지만, 원본 사진을 찾을때는 뭐가 진짜인지 구분하지 못한

![13](/assets/img/2023-03-14-CS231n---Lecture-2.md/13.png)



#### Curse of dimension(차원의 저주)

- KNN이 잘 작동하기 위해서는 **전체 공간을 조밀하게 커버할 수 있을 정도의 데이터가 필요하다**

	![14](/assets/img/2023-03-14-CS231n---Lecture-2.md/14.png)

	- `1차원 에서는 4개`의 데이터가 필요 했다면,
	- `2차원 에서는 4 * 4 = 16개`의 데이터가,
	- `3차원 에서는 4 * 4 * 4 = 64개`의 데이터가 필요하다.
- **고차원으로 갈 수록 기하급수적인 데이터가 필요**하다

---



### Linear Classification

- **Linear Classification** 은 단순하지만 이후에 배우게 되는 **Neural Network**와 **CNN**의 기반이 되는 알고리즘입니다. 즉 아래 그림과 같이 `기본 블럭`이 되는 것입니다.

![15](/assets/img/2023-03-14-CS231n---Lecture-2.md/15.png)



### Parametric Approach

- Linear Classification은 **"Parametric model"** 의 가장 기본적인 형태이다
	- Parametric Model
		- 데이터가 특정 분포를 따른다고 가정하고, 우리가 학습을 하면서 결정해야 하는 파라미터의 종류와 수가 명확하게 정해져 있다. → 데이터가 얼마나 많든 간에 결정해야 할 파라미터의 수는 변하지 않는다.
		- 우선 모델의 형태를 정하고, 이 모델의 파라미터를 학습을 통해 발전시켜나가는 식으로 알고리즘이 진행된다.
		- Linear regression, Logistic Regression, Neural Network 등, 모델이 학습해야 하는 것이 명확히 정해져 있기 때문에 속도가 빠르고, 모델을 이해하기가 쉽다는 장점이 있다.. 하지만 속도가 느린 경우가 많고, 더 큰 데이터를 필요로 하는 경우가 있으며 모델이 왜 그런 형태가 되었는지에 대한 명확한 설명을 하기가 쉽지 않다.
	- Non-Parametric Model
		- 데이터가 특정 분포를 따른다는 가정이 없기 때문에 우리가 학습에 따라 튜닝해야 할 파라미터가 명확하게 정해져 있지 않은 것이다. → data에 대한 사전 지식이 전혀 없을 때 유용하게 사용될 수 있다.
		- Decision tree, Random forest, K-nearest neighbor classifier 등, 데이터가 특정한 분포를 따른다는 가정을 하지 않기 때문에 더 flexible하다는 장점이 있다. 하지만 속도가 느린 경우가 많고, 더 큰 데이터를 필요로 하는 경우가 있으며 모델이 왜 그런 형태가 되었는지에 대한 명확한 설명을 하기가 쉽지 않다.
- 위에 Parametric model 값을 단순하게 **"Wx + b"** 와 같이 선형적으로 사용하는 것을 바로 **Linear Classification**이라고 한다

	![16](/assets/img/2023-03-14-CS231n---Lecture-2.md/16.png)

1. `X`: Input Image
	- `X의 크기 : 32x32x3 = 3072x1 크기`를 가지는 고양이 사진을 사용한다
2. `W`: 가중치(Weight Parameter) 값
	- 만약 분류할 동물의 **클래스 수가 10개** 라고 하자
	- Dimension 크기를 맞춰주기 위해서 `W의 크기 : 10x3072`를 가진다
3. `b`: 편향(Bias) 값
	- Bias(편향치)는 x와 W의 곱한 결과에 이 값을 더해준다
	- `Bias 크기: 10x1`를 가지는 것을 볼 수 있다 (Class 갯수)
	- 이 Bias는 데이터와 무관하게 **특정 클래스에 "우선권"을** 부여한다
	- 예) **데이터셋이 불균등한 상황** : 고양이 사진이 개 사진보다 많은 경우


### Linear Classification 과정 예시


![17](/assets/img/2023-03-14-CS231n---Lecture-2.md/17.png)

1. `X`: 입력 이미지
	- `X의 크기: 4x1`로 1차원으로 편다
2. `W`: 가중치 값(Weight Parameter)
	- `W의 크기: 3x4`로 **(클래스 갯수) x (입력 데이터 크기)** 이다
	- **각 행(row)은 하나의 클래스를 담당** 하므로 이를 **템플릿**으로 볼 수 있다
	- 여기서 `W의 행 백터와 입력값 간에 내적`을 계산하는데, 이것이 `각 클래스 간 템플릿의 유사도`를 측정하는 것으로 볼 수 있다
3. `b`: Bias 값
	- `Bias의 크기: 3x1`로 **(클래스 갯수) x 1** 이다
	- 이 값은 독립적으로 **각 클래스의 scaling offset** 를 더해주는 것과 같다


### Linear Classification 해석 - Weight의 템플릿 값


![18](/assets/img/2023-03-14-CS231n---Lecture-2.md/18.png)

- CIFAR-10 이라는 데이터셋을 이용하여 Linear Classification를 학습한 결과이다
- 가장 아래 보이는 10개의 그림은 **각각 템플릿의 weight 값**을 나타낸 것이다
- weight 값은 각 class에 있는 모든 이미지를 평균화 시키므로 **다양한 모습의 사진이 있지만 하나의 템플릿 값만 가진다**
	- 자동차(car)의 템플릿(weight)값을 보면 진짜 자동차와 같은 모습을 볼 수 있다
	- 말(Horse)은 데이터 속에 왼쪽, 오른쪽 모습이 모두 있을 수 있어 이것이 겹쳐서 보인다


### Linear Classification 해석 - 이미지를 고차원에서 하나의 점으로


![19](/assets/img/2023-03-14-CS231n---Lecture-2.md/19.png)

- 또 다른 관점은 이미지를 고차원에서 하나의 점으로 생각하는 것이다. 이러한 관점으로 Linear Classification을 해석하면 아래 그림과 같다
	1. `W`: 가중치 값 - **각 선분의 기울기**
	2. `b`: Bias 값 - **선분의 시작 offset 값**
- **각 class는 선분을 가지며 이러한 선을 기준으로 분류** 하는 것으로 해석할 수 있다
- 하지만 특별한 상황에서는 예측하기 어려울 수 있다(Multimodal)


### Hard cases for a linear classification

- Linear Classification으로 풀 수 없는 어려운 경우가 존재합니다.
- 순서대로 `Partity Problem(Xor)`, `도넛 형태`, `Multimodal Problem` 이다. 이러한 경우 Linear Classification 으로 풀 수 없는 문제이다

![20](/assets/img/2023-03-14-CS231n---Lecture-2.md/20.png)

