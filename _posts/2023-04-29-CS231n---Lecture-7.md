---
layout: single
date: 2023-04-29
title: "CS231n - Lecture 7"
use_math: true
tags: [강의/책 정리, ]
categories: [AI, ]
---


## Lecture 7 | Training Neural Networks Ⅱ



## Optimization



#### **Gradient Descent**


![0](/assets/img/2023-04-29-CS231n---Lecture-7.md/0.png)_Gradient Descent 코드_


![1](/assets/img/2023-04-29-CS231n---Lecture-7.md/1.png)_Gradient Descent 코드_


![2](/assets/img/2023-04-29-CS231n---Lecture-7.md/2.png)_Gradient Descent_



#### **SGD (Stochastic Gradient Descent)**


**SGD의 문제는 무엇이 있을까?**

1. **Zigzag (Poor Conditioning)**

	![3](/assets/img/2023-04-29-CS231n---Lecture-7.md/3.png)


**loss함수가 한 방향으로만 민감하다**


→ loss가 빠르게 변하는 차원으로만 지저분하게 움직이면서 최적화됨


→ loss에 영향을 덜 주는 차원은 느리게 변함


실제 loss함수는 차원이 아주 많기 때문에, 제대로 학습되지 않을 가능성이 높다.

1. **local minimum**

![4](/assets/img/2023-04-29-CS231n---Lecture-7.md/4.png)


![5](/assets/img/2023-04-29-CS231n---Lecture-7.md/5.png)


![6](/assets/img/2023-04-29-CS231n---Lecture-7.md/6.png)

- SGD 방식을 비롯한 GD 방식은, local minimum을 찾아가는 알고리즘이기 때문에, 위와 같은 상황에선 제대로 된 optimization X
- gradient가 0이고, opposite gradient도 0이기 때문
1. **Saddle point**

![7](/assets/img/2023-04-29-CS231n---Lecture-7.md/7.png)


![8](/assets/img/2023-04-29-CS231n---Lecture-7.md/8.png)


![9](/assets/img/2023-04-29-CS231n---Lecture-7.md/9.png)

- `Saddle Points` - 한쪽 방향으로는 증가하고 다른 한쪽 방향으로는 감소하는 지역
- 매우 큰 Neural Network에서 Local Minima는 모든 방향의 전부 Loss가 상승하는 방향

	→ 고차원 공간에서는 Local Minima보다 Saddle Point에 취약하다. 


	→ **실제로 더 자주 일어나는 문제**

- 이 경우도 gradient 0이기 때문에, 멈춰버리고, saddle point 근처는 또한 update가 아주 느림
1. **Stochastic의 한계 - Noise 문제**

![10](/assets/img/2023-04-29-CS231n---Lecture-7.md/10.png)

- Loss를 계산할 때마다 데이터 전부를 이용하기 어려워서 실제로는 미니배치 데이터들의 Loss를 계산하고 실제 Loss를 추청하는 `Gradient Noisy Estimate`만 구한다
- 여기서 발생하는 Noise가 존재

(Full Batch) **GD가 해결책?**

- Taco Shell 문제 O
- Noise → 네트워크의 Explicit Stochasticity로 발생
- Saddle points

	해결 X



#### SGD+Momentum


![11](/assets/img/2023-04-29-CS231n---Lecture-7.md/11.png)


![12](/assets/img/2023-04-29-CS231n---Lecture-7.md/12.png)


![13](/assets/img/2023-04-29-CS231n---Lecture-7.md/13.png)


![14](/assets/img/2023-04-29-CS231n---Lecture-7.md/14.png)


**velocity를 유지**하도록 Momentum이라는 개념을 도입


→ Hyperparameter $\rho$


→ 높은 값으로 맞춰줌 (0.9, 0.99)


→ velocity vector 방향 나아감


![15](/assets/img/2023-04-29-CS231n---Lecture-7.md/15.png)_SGD의 문제점 해결 - 1_


![16](/assets/img/2023-04-29-CS231n---Lecture-7.md/16.png)_SGD의 문제점 해결 - 1_


![17](/assets/img/2023-04-29-CS231n---Lecture-7.md/17.png)_SGD의 문제점 해결 -2_

1. `Local Minima & Saddle Point`

	공이 Local Minima나 Saddle Point에 도달해도 여전히 Velocity를 가지고 있어서 Gradient = 0이라도 움직일 수 있고, Local Minima를 극복하고 계속 내려갈 수 있다.

2. `Poor Conditioning`

	업데이트가 잘 안되어 지그재그로 움직인다면 Momentum이 이 변동을 서로 상쇄시킨다. 이를 통해서 Loss에 민감한 수직 방향의 변동은 줄여주고 수평방향의 움직임은 점차 가속화된다. 따라서 momentum을 추가하게 되면 high condition number problem을 해결하는 데 도움이 된다.

3. `Noise`

	Momentum을 추가해서 Velocity가 생기면 Noise는 평균화된다. 보통의 SGD가 구불구불 움직이는 것에 비해서 Momemum은 Minima를 향해서 더 부드럽게 움직인다.


**Momentum을 구하는 방식?**


![18](/assets/img/2023-04-29-CS231n---Lecture-7.md/18.png)


![19](/assets/img/2023-04-29-CS231n---Lecture-7.md/19.png)


![20](/assets/img/2023-04-29-CS231n---Lecture-7.md/20.png)_Nestrov Momentum_


Gradient 구할 때


**→ 어느 시점에서 구할지?**


**Nestrov Momentum**


![21](/assets/img/2023-04-29-CS231n---Lecture-7.md/21.png)


velocity로 **이동한 후의 시점에서의 gradient를 구함**


(Velocity Vector를 예측하고 그 지점에서의 Gradient Vector를 계산하고 원점으로 돌아가 이 둘의 가중 평균으로 이동)


→ velocity 방향 잘못되었을 경우, gradient 방향을 좀 더 활용할 수 있음


→ **Convex(볼록) optimization에서는 뛰어난 성능**이지만, non-convex problem (like neural network)에서는 보장 X


→ velocity의 초기값은 0

- $x_{t+1} = x_t+v_{t+1}$ 에서, $v_{t+1}$은 어떻게 구할 수 있을까?

	$v$ 는 현재 움직이는 방향의 추이를 활용하기 위한 변수로, 


	$v_{t+1}$는 **현재의 방향으로 이동한 후의 시점**에서의 **gradient를 계산**해서 현재의 $v_t$와 합쳐서 구해준다


	⇒ $v_{t+1} = \rho v_t - \alpha\triangledown f(x_t+\rho v_t)$  // 첫번째 항이 현재의 velocity, 두번째 항이 이동 후의 gradient

- let $\tilde x_t = x_t + \rho v_t$ 즉, 현재 velocity로 이동했을 시의 위치라고 하자

	⇒ $v_{t+1} = \rho v_t - \alpha\triangledown f(\tilde x_t)$


![22](/assets/img/2023-04-29-CS231n---Lecture-7.md/22.png)

- $\tilde x_{t+1}$과 $\tilde x_t$ 사이의 관계는?

	$\tilde x_{t+1} = \tilde x_t - \rho v_t + (1+\rho)v_{t+1} = \tilde x_t + v_{t+1} + \rho (v_{t+1}-v_t) $ 


![23](/assets/img/2023-04-29-CS231n---Lecture-7.md/23.png)_overshooting이 덜 한 것을 볼 수 있다._

- 평평한 minima에 도달하게 됨

→ momentum 때문에 좁고 깊은 minima는 지나침

- training data의 변화에 강인함

→ 일반화에 더 강점 (but NN에선 사용 X)



#### AdaGrad


![24](/assets/img/2023-04-29-CS231n---Lecture-7.md/24.png)_AdaGrad 방식_


![25](/assets/img/2023-04-29-CS231n---Lecture-7.md/25.png)_SGD, SGD - momentum 방식_

- 훈련 도중 계산되는 gradients의 누적치를 활용

	velocity term X이 아닌, **grad squared term 이용**


	**update 시 update term을 gradient 제곱 항으로 나눠 step size를 줄여줌**

- **gradient가 Large 한 dimension → 느리게** (분모에 gradient 제곱항이 있기 때문)
- **t가 늘어나면, 값이 점점 작아짐 →**서서히 증가
- convex 경우 minimum에 수렴할 수 있게 하면 좋음

	non-convex에선 문제 / saddle point에서 멈출 수 있음 (momentum x)


그렇기 때문에 자주 쓰진 않음



#### **RMSProp**


![26](/assets/img/2023-04-29-CS231n---Lecture-7.md/26.png)

- AdaGrad의 누적값에 **decay_rate 곱해줌**

	step 속도 가속/감속 → **점점 속도가 줄어드는 문제 해결 (decay_rate)**

- gradient 제곱 계속 나눠준다는 점에서 Adagrad와 유사

![27](/assets/img/2023-04-29-CS231n---Lecture-7.md/27.png)


Q. Convex인데 왜 Adagrad에게 불리한가? 


Learning rates가 서로 다르기 때문이다. 여러 알고리즘 간에 '같은 Learning rates'를 가지고 AdaGrad를 Visualization하는 것은 공정하지 못하다. 시각화를 하고자 한다면 알고리즘 별로 Learning Rate를 조정하는 것이 좋다.



#### **Adam**


![28](/assets/img/2023-04-29-CS231n---Lecture-7.md/28.png)


**두 moment 값을 사용 (AdaGrad와 RMSProp을 조합)**

- first moment: gradient의 가중 합 (velocity 의미)
- second moment: AdaGrad / RMSProp 처럼 gradients 제곱 이용 (gradient의 제곱 항)

⇒ RMSProp + momentum


⇒ 이 두 moments를 통해 이전의 정보(Estimate)를 저장함

- beta1, beta2는 각자의 decay rate값

**problem?**

- 초기 moment 값들을 0으로 초기화

	→ 1회 update 후, 여전히 0에 가까움 


	→ 이 때문에 초기 step 엄청 커짐


	→ 손실함수가 가파르기 때문이 아니라 **0으로 초기화했기 때문** (알고리즘적 문제)


	(first로 인해 상쇄될수도 있지만, 문제가 생길수도)


→ 문제 해결을 위해  **bias correction term 추가**


	**현재 스텝에 맞는 적절한 unbiased term 계산**


⇒ **기본 알고리즘으로 사용** (다양한 문제에 정말 잘 작동함)


![29](/assets/img/2023-04-29-CS231n---Lecture-7.md/29.png)


**Adam을 비롯한 손실함수들이 해결하지 못하는 것?**


→ **타원형 손실함수**


각 차원마다 적절하게 속도 높이고 줄이면서 독립적으로 step 조절


타원이 축 방향으로 정렬되어 있지 않고 기울어져 있다?


Adma은 차원에 해당하는 축 만을 조절할 수 있음


차원을 회전시킨 다음에 수평/수직 축으로만 늘렸다 줄였다 하는 것


![30](/assets/img/2023-04-29-CS231n---Lecture-7.md/30.png)



## **learning rate** 


![31](/assets/img/2023-04-29-CS231n---Lecture-7.md/31.png)


→ 적절한 hyperparameter 찾는 것이 중요함


**how?**


**→ 처음엔 높게, 학습 진행할수록 점점 낮추기**


![32](/assets/img/2023-04-29-CS231n---Lecture-7.md/32.png)

- step decay → 특정 iter에서 낮추기
- 1/t decay → time step에 따라 꾸준히 낮추기
- 갑자기 내려가는 지점이 Learning rate decay의 지점을 의미

	(learning rate가 너무 높아 깊게 들어가지 못하는 부분인데, learning rate를 낮춰 해결)

- **SGD Momentum 시에 자주 사용**

	(Adam땐 자주 사용 x)

- **second-order hyperparameter (처음엔 고려하지 않음; 너무 복잡해지기 때문에)**
	1. 없이 학습
	2. curve를 보고 필요한 부분에 하기
