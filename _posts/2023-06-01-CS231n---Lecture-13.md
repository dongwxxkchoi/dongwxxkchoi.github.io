---
layout: single
date: 2023-06-01
title: "CS231n - Lecture 13"
use_math: true
author_profile: false
tags: [강의/책 정리, ]
categories: [AI, ]
---


## Unsupervised Learning



#### **Unsupervised Learning(비지도 학습)**이란?

- **Data:** **X**

	오직, **sample**만 존재 (label 無)

- **Goal:** Learn some underlying hidden structure of the data

	**데이터에 숨어있는 기본적인 구조**를 학습

- **Examples**

![0](/assets/img/2023-06-01-CS231n---Lecture-13.md/0.png)_군집화 (clustering)_


![1](/assets/img/2023-06-01-CS231n---Lecture-13.md/1.png)_군집화 (clustering)_

- 일정 metric을 가지고 유사한 데이터들끼리 묶어주는 것 (grouping)

![2](/assets/img/2023-06-01-CS231n---Lecture-13.md/2.png)_차원축소 (PCA; 주성분 분석)_


![3](/assets/img/2023-06-01-CS231n---Lecture-13.md/3.png)_차원축소 (PCA; 주성분 분석)_

- 학습 데이터가 가장 많이 퍼져있는 축(분산이 큰 축)을 찾아내고, 그 축은 데이터에 숨어있는 구조의 일부분을 의미
- 차원 축소에도 이용 (중요한 정보들의 보존은 필수)

![4](/assets/img/2023-06-01-CS231n---Lecture-13.md/4.png)_오토인코더 _


![5](/assets/img/2023-06-01-CS231n---Lecture-13.md/5.png)_오토인코더 _

- feature representation

→ Loss:  입력 데이터를 얼마나 잘 구성했는지


→ 이를 이용해 특징들을 학습할 수 O


![6](/assets/img/2023-06-01-CS231n---Lecture-13.md/6.png)_분포 추정_


![7](/assets/img/2023-06-01-CS231n---Lecture-13.md/7.png)_분포 추정_

- 기본적인 분포를 추정

→ 점들이 더 많이 밀집되어 있는 곳의 분포가 더 크도록 이들의 분포를 적절히 모델링 

undefined

#### Supervised Learning vs Unsupervised Learning


![8](/assets/img/2023-06-01-CS231n---Lecture-13.md/8.png)


**<특징>**

- data의 비용(cost)이 적음

	→ 아주 많은 데이터를 모을 수 있음 

- data의 숨겨진 구조들을 잘 학습해 세계의 구조를 이해하는 것이 목표


## Generative Models



#### **생성 모델(Generative Models)이란?**

- 비지도 학습의 일종
- **동일한 분포에서 새로운 샘플들을 생성해 내는 것**이 목표

![9](/assets/img/2023-06-01-CS231n---Lecture-13.md/9.png)

- $P_{model}$을 학습시켜 $P_{data}$와 같은 데이터를 생성해내도록

	이를 위해, $P_{model}$이 $P_{data}$와 **유사해지게** 만들어야 하고, 또한 **분포 추정**이 필요함


	**⇒ 비지도 학습의 핵심**

- **분포 추정의 전략**
	1. $P_{model}$의 분포를 명시적으로 정의하기 (explicitly)
	2. $P_{model}$의 분포를 간접적으로 정의하기 (implicitly)
- **왜 중요한가?**

	![10](/assets/img/2023-06-01-CS231n---Lecture-13.md/10.png)


	→ **고품질의 사실적인 (realistic) 샘플들을 생성**해낼 수 있다면 많은 것 가능

	- super resolution
	- colorization (밑그림에 색 채워 실제 모습 추정)
	- 강화학습을 이용한 simulation
	- planning을 위한 시계열 데이터 생성
	- latent representations 추정

		→ 잠재 특성을 다른 task에 활용



#### 생성 모델의 종류


![11](/assets/img/2023-06-01-CS231n---Lecture-13.md/11.png)_GAN’s taxonomy_


**명시적 분포**

- PixelRNN/CNN

	계산 가능한 확률 모델 사용 (Tractable density)

- VAE (Variational Auto-Encoder)

	근사적 밀도 추정 (Approximate density)


**암묵적 분포**

- GAN(Generative Adversarial Networks)

	간접적인 분포 추정 (Implicit dencity)



## **Pixel RNN / CNN**



#### Pixel RNN/CNN이란?

- **fully visible brief networks**의 일종

	![12](/assets/img/2023-06-01-CS231n---Lecture-13.md/12.png)

	- 밀도를 **명시적으로 정의**하고 모델링
	- 이미지 데이터 X에 대한 **likelihood**: $p(x)$ 를 모델링

		→ chain rule로 1차원 분포들 간의 곱 형태로 분해


		$p(x_1)\times p(x_2|x_1)\times p(x_3|x_1, x_2)\times ... \times p(x_n|x_1,...,x_{n-1})$


		⇒ 모든 픽셀들의 likelihood의 곱으로 joint likelihood를 표현

	- 이를 바탕으로 likelihood를 최대화시킴

		**⇒ 어떻게 모델링? : Neural Networks**


		**⇒ 픽셀들의 순서? : 모든 이전 픽셀들**을 어떻게 고려?


		⇒ 이 문제를 풀기 위해 고안된 **PixelRNN**



#### **Model - PixelRNN**


![13](/assets/img/2023-06-01-CS231n---Lecture-13.md/13.png)


![14](/assets/img/2023-06-01-CS231n---Lecture-13.md/14.png)


![15](/assets/img/2023-06-01-CS231n---Lecture-13.md/15.png)


![16](/assets/img/2023-06-01-CS231n---Lecture-13.md/16.png)


![17](/assets/img/2023-06-01-CS231n---Lecture-13.md/17.png)

- 특징
	- 각 그리드 → 이미지의 픽셀들
	- 좌상단 코너부터 시작 → 대각선 아래 방향으로
	- 화살표 방향으로의 **연결성을 기반**으로 순차적으로 픽셀을 생성함
		- 이 **종속성**을 **RNN (LSTM)을 이용해 모델링**함
	- 단점
		- 순차적인 생성 방식이기 때문에 느림
		- 한 이미지의 생성에 여러 번의 feed forward가 필요


#### **Model - PixelCNN**


![18](/assets/img/2023-06-01-CS231n---Lecture-13.md/18.png)

- **특징**
	- 모든 종속성을 고려하는 RNN 대신, **CNN**으로 모델링

		⇒ 픽셀 생성시, **특정 픽셀만을 고려해서 생성**

	- 각 픽셀 단위 CNN에서의 Softmax Loss를 계산해 likelihood를 최대화하는 pixel output

		**→ 비지도 학습인데 정답 값 (ground truth) 존재?**

			- input image를 label로 활용
			- 주변의 pixel들로 부터 **생성한 pixel**과 **input 간의 차이를 계산**하는 것
			- 이를 통해 모델을 학습시키는 것
	- PixelRNN보다 학습이 빠름
		- train time : 학습 데이터 이미 모두 알고 있음

			→ 병렬화 이용 빠른 연산

		- **test time** : 여전히 좌측 상단에서 부터 시작

			→ **여전히 순차적 처리**


			→ 처음 픽셀의 분포가 이후 모든 분포에 큰 영향 

				- uniform distribution 이용
				- 첫 픽셀만 train data에서 가져옴

![19](/assets/img/2023-06-01-CS231n---Lecture-13.md/19.png)_PixelCNN을 통해 생성한 결과 - 개선의 여지 많이 보임_


→ 특히 의미론적 부분이 명확하지 않음 


![20](/assets/img/2023-06-01-CS231n---Lecture-13.md/20.png)


**PixelRNN / PixelCNN**

- **likelihood p(x)를 명시적으로 계산하는 방법**

	→ 최적화 가능한 분포 (밀도) 계산

- evaluation metric 존재해, 평가에 좋음
- 느림

	→ audio generation 등에도 사용 but 느림



## VAE (Variational Autoencoders)



#### **VAE?**

- 다루기 힘든 (intractable) **잠재 변 z의 밀도 함수** (density function)를 정의한다.

	![21](/assets/img/2023-06-01-CS231n---Lecture-13.md/21.png)_data likelihood p(x)_


	→ 가능한 모든 z값에 대한 기댓값을 구한다.


	→ 직접 최적화 (optimize)할 수 없으므로 lower bound를 구해서 최적화하는 방식을 사용한다.

- **Autoencoders**와 관련이 있음

	### **Autoencoders?** 


	![22](/assets/img/2023-06-01-CS231n---Lecture-13.md/22.png)

	- 비지도학습(Unsupervised Learning)의 일종
	- **Encoder 부분**과 **Decoder 부분**으로 구성
		- **Encoder**

			보통, DNN을 통해 input data인 **x를 더 작은 차원의 z로 mapping**


			→ **차원 축소**의 효과

				- **z**가 **데이터 x의 중요한 feature들을 학습**할 수 있음
		- **Decoder**

			Encoder를 거치면서 **압축된 z를 다시 복원해서** $x$**와 유사하면서 같은 차원인** $\hat x$**를 잘 복원하도록 학습**


			(사용될 수 있는 특징들을 학습하는 방식 취함)

	- Encoder와 Decoder는 대칭적
		- 가령, Encoder가 Conv로 구성되었다면, Decoder는 Upconv로 복원

			(완벽히 대칭이어야 하는 것은 아님)

	- 입력의 복원을 위해선 L2 loss 함수를 사용함

		![23](/assets/img/2023-06-01-CS231n---Lecture-13.md/23.png)

		- input data $x$ 로 생성한 $\hat x$와의 loss를 계산하기 때문에, **label이 필요없다.**

	![24](/assets/img/2023-06-01-CS231n---Lecture-13.md/24.png)

	- test time에 decoder는 사용하지 않고, **encoder를 통해 압축한** $z$**를 활용**해 다른 **task에 맞게 fine-tune 해서 활용**한다.

		ex. classifier


		![25](/assets/img/2023-06-01-CS231n---Lecture-13.md/25.png)


	**⇒ Auto-Encoder는 학습 데이터의 variation을 잘 포착해낼 수 있다.**


		잠재 변수인 z가 잘 담음


	**유사한 방식으로 새로운 이미지를 생성해 낼 수는 없을까?**


	**⇒ Variational Auto Encoders 등장**



### Variational Autoencoders


![26](/assets/img/2023-06-01-CS231n---Lecture-13.md/26.png)

- 명시적 분포 有
- training data / output: $\{x^{(i)}\}^N_{i=1}$

	latent variable: $z$


	즉, latent variable인 $z$로부터 output인 $x$를 생성해내는 방법

- AE와 같이 $z$**의 각 요소들은 데이터의 변동 요소들을 잘 포착**

	ex. $x$: 얼굴


		$z$: 얼마나 웃고 있는지 정도, 눈썹의 위치, 머리 방향 등등


	→ 이런 요소들을 train time에 학습해내어, test time에 이들을 통해 원하는 것을 생성

- **sampling**
	- $z$**의 prior로부터** $z$**의 sampling**을 수행함

		→ 이 prior로 주로 gaussian distribution을 선택 (합리적 선택)

	- conditional distribution이자 likelihood인 $p(x|z)$**에서 샘플링해 데이터** $x$**를 생성**

		(neural network로 sampling)

- **Intractability**

	![27](/assets/img/2023-06-01-CS231n---Lecture-13.md/27.png)


	→ 이 marginal likelihood를 구하려면 적분이 필요한데, **복잡한 분포여서 적분 힘듦**


	![28](/assets/img/2023-06-01-CS231n---Lecture-13.md/28.png)


	→ 또한, $z$**의 추론**을 위해 


	이 **posterior를 구해야 할 때**도, marginal likelihood인 $p_\theta(x)$가 쓰이는데, 구할 수가 없다


	<u>**⇒ 구할 수 없는**</u> $p_\theta(z|x)$<u>**를 구하려 하지 말고, 추가적인 encoder network인**</u> $q_\phi(z|x)$<u>**를 정의해 근사시키자**</u>


	→ 이렇게 해서 데이터의 확률론적 생성모델을 만드는 것

- **Model (Network)**

	![29](/assets/img/2023-06-01-CS231n---Lecture-13.md/29.png)

	- **Encoder (**$q_\phi(z|x)$ **(parameters** $\phi$**) )**

		input $x$의 $\mu_{z|x}$ (평균)와 $\Sigma_{z|x}$ (대각 공분산)으로 부터, $z$를 sampling한다.


		($z|x \sim \mathcal{N}(\mu_{z|x}, \Sigma_{z|x})$

	- **Decoder (**$p_\theta(x|z)$ **(parameters** $\theta$**) )**

		encoder의 output인 $z$의 $\mu_{x|z}$ (평균)와 $\Sigma_{x|z}$ (대각 공분산)으로 부터, $x|z$를 sampling한다.


		($x|z \sim \mathcal{N}(\mu_{x|z}, \Sigma_{x|z})$


	⇒ network는 이렇게 구성되는데, 어떻게 근사?

- **marginal likelihood**

	![30](/assets/img/2023-06-01-CS231n---Lecture-13.md/30.png)


	($z$에 대한 기댓값을 취해, 근사한다.)


	![31](/assets/img/2023-06-01-CS231n---Lecture-13.md/31.png)


	(Bayes’ Rule을 적용해 변형함 $p(z|x) = \frac{p(x|z)p(z)}{p(x)}$)


	![32](/assets/img/2023-06-01-CS231n---Lecture-13.md/32.png)


	그 후, 적당히 변형을 취해주면 다음의 식이 나온다.


	![33](/assets/img/2023-06-01-CS231n---Lecture-13.md/33.png)


	---


	[bookmark](https://angeloyeo.github.io/2020/10/27/KL_divergence.html)


	여기서 나오는 $D_{KL}$은 KL divergence라는 수치로, 두 확률 분포가 얼마나 가까운지를 측정하는 척도라고 할 수 있다.


	---

	- $\mathbf{E}_x[log~p_\theta(x^{(i)}|z)]$ : decoder network의 output (re-param trick을 통해 derivative함)
	- $-D_{KL}(q_\phi(z|x^{(i)})||p_{\theta}(z))$ : encoder와 gaussian prior 간의 분포 차이

		→ closed form solution

	- $D_{KL}(q_\phi(z|x^{(i)})||p_{\theta}(z|x^{(i)}))$

		**→ intractable** 


		→ $p_\theta(z|x^{(i)})$는 여전히 구할 수 없음


		⇒ 하지만 이 식은 0보다 큰 것이 보장되기 때문에 (KL divergence는 0보다 큼)


	![34](/assets/img/2023-06-01-CS231n---Lecture-13.md/34.png)


	다음과 같이 계산할 수 있는 첫항과 두번째 항을 최적화 시키는 문제로 바꿀 수 있고,


	앞의 두 항은 **tractable lower bound** 즉, 구할 수 있는 **하한**이기 때문에, 이 값을 최대화시킨다면, 전체 데이터의 log marginal likelihood를 최대화하는 효과를 갖는다.


	![35](/assets/img/2023-06-01-CS231n---Lecture-13.md/35.png)


	![36](/assets/img/2023-06-01-CS231n---Lecture-13.md/36.png)


	첫 항을 높이기 위해, input data를 재구성하고,


	둘째 항을 높이기 위해, 두 분포를 최대한 가깝게 만든다. (같을 때 0, 멀어질수록 값 커짐; negative라서 KL divergence 값이 작아져야 전체 값이 커짐)

- **Final Model**

	![37](/assets/img/2023-06-01-CS231n---Lecture-13.md/37.png)

- **Generating**

	![38](/assets/img/2023-06-01-CS231n---Lecture-13.md/38.png)


	Generating시(test time)에는 encoder를 제외하고 $z$ 이후의 decoder만 사용해 image를 생성


	→  $z$를 posterior였던 $p_\theta(x|z)$에서 sampling


	![39](/assets/img/2023-06-01-CS231n---Lecture-13.md/39.png)


	![40](/assets/img/2023-06-01-CS231n---Lecture-13.md/40.png)


	생성한 결과를 보면, 잠재 속성을 기반으로 2차원에 펼쳐 놓았을 때, feature $z_1$과 $z_2$의 조합으로 이미지들을 생성했다.


	이렇게 독립적 해석 가능 요소들에 의해 인코딩할 수 있다는 장점이 있다.


	또한, $q_\phi(z|x)$ encoder network에 새 $x$를 넣어 $z$로 매핑시켜 classification 등의 다른 task에 사용할 수 있다.


	![41](/assets/img/2023-06-01-CS231n---Lecture-13.md/41.png)


	하지만 아직, 다른 모델들에 비해 **blurry**하다

- **Summary**

	![42](/assets/img/2023-06-01-CS231n---Lecture-13.md/42.png)

	- AE의 확률론적 변형 버전으로 데이터 생성을 위해 분포와 샘플링의 개념이 추가됨
	- intractable 분포를 다루기 위해 variational lower bound 계산 (근사)

	**장점**

	- 원칙적 접근 방법

		→ 모델에서 q(z|x)를 추론


	**단점**

	- lower bound를 계산

		→ 직접 최적화 방법이 부족함

	- blurry, quality가 낮음

	**최근 흐름**


	diagonal Gaussian 대신 richer approximate posteriors 이용해보자


	→ 잠재변수에 더 많은 구조적 정보 담으려는 시도


	→ 독립적인 것이 아니라 구조 모델링하거나 서로 grouping 하기도 했음



## GAN (Generative Adversarial Networks)



#### GAN?

- 직접 확률분포를 모델링 X

	→ 게임 이론의 접근법을 취해 2-player game 방식으로 학습 분포 학습함 

- 복잡한 고차원 학습 분포에서 샘플링은 불가능

	→ 단순한 gaussian random noise에서 sampling해서, **원하는 복잡한 학습 분포로 transformation하는 함수를 학습**하자


	(복잡한 분포 → neural network)

- random noise vector ($z$)를 입력 받아, 벡터 차원 수를 명시

	→ $z$가 생성 network 통과 후 학습 분포로부터 직접 샘플링된 값 출력


	모든 random noise 입력이 학습 분포의 샘플에 매핑되길 원함


	![43](/assets/img/2023-06-01-CS231n---Lecture-13.md/43.png)

- **GAN이란?**

	![44](/assets/img/2023-06-01-CS231n---Lecture-13.md/44.png)

	- 학습 방법으로 two player game을 생각
		- **generator**

			: player 1으로 참여해, 사실적 이미지를 생성해 discriminator를 속이는 것이 목표

		- **discriminator**

			: player 2로 참여해, input으로 받은 이미지가 실제인지, 거짓인지의 구별이 목표

	- 만약, discriminator가 구별을 잘 하면, generator는 더 실제 같은 가짜 이미지를 만들어야 하므로, 아주 좋은 generator 모델이 됨
	- step
		1. random noise가 generator의 입력으로 들어감
		2. generator는 fake images를 생성
		3. fake images와 real images가 discriminator network의 입력으로 들어감
		4. discriminator가 구별을 해서 잘 맞출 수 있도록 update

		→ 이 과정의 반복임

- **수식**

	![45](/assets/img/2023-06-01-CS231n---Lecture-13.md/45.png)

	- jointly 학습
		- generator network인 G는 parameter인 $\theta_g$를 최소화함
		- discriminator network인 D는 parameter인 $\theta_d$를 최대화함
	- **expectation**  $E[log~D(x)]$
		- $log~D(x)$는 **실제 데이터** $x$에 대한 discriminator 출력 값
		- 실제 데이터 분포 $p_{data}$에서 sampling
	- $P(z)$를 따르는 $z$에 대한 기댓값 (expectation)의 $z\sim p(z)$는 generator에서 sampling
	- $D(G(z))$ : 생성된 가짜 이미지에 대한 discriminator의 출력

	이들을 최대화시키는 파라미터 $\theta_d$를 찾아야 함

	- $D(x)$의 경우는 실제 데이터이므로 값이 1이면 좋음 (True라고 판정해야)
	- $D(G(z))$는 0일수록 좋음 (False라고 판정해야)

		(Generator의 이미지를 어떻게 판정했는지)

- **Questions?**
	- 이 network의 학습을 위해 레이블 필요?

		→ No. unsupervised


		→ 생성한 것은 가짜라는 의미의 0, 실제는 진짜라는 의미의 1이라는 label이 있지만, 추가적인 label은 아님

- **학습**

	정해진 규칙은 없지만, 일단 generator와 discriminator를 번갈아가며 학습함


	objective function을 최대화하는 $\theta$를 위해


	discriminator는 gradient ascent


	generator는 gradient descent


	⇒ 이 둘을 번갈아가며 학습함

- **문제점**

	![46](/assets/img/2023-06-01-CS231n---Lecture-13.md/46.png)

	- loss가 높은, 즉 discriminator와 generator의 성능이 좋지 않은 초반에, gradient가 오히려 낮기 때문에 학습이 더디게 일어난다.

	![47](/assets/img/2023-06-01-CS231n---Lecture-13.md/47.png)

	- 이를 해결하기 위해, discriminator가 맞출 likelihood를 최소화하는 일반적인 방법이 아닌, discriminator가 틀릴 likelihood를 최대화하는 방법을 사용

		→ bad sample일때의 gradient가 커져 학습이 잘 됨

- **Total**

	![48](/assets/img/2023-06-01-CS231n---Lecture-13.md/48.png)


	위의 예시처럼, discriminator를 먼저 학습시키다가, discriminator를 고정시키고 generator를 학습시키기도 하고, k를 바꾸는 등의 다양한 방법이 존재함

- **Results**

	![49](/assets/img/2023-06-01-CS231n---Lecture-13.md/49.png)


	![50](/assets/img/2023-06-01-CS231n---Lecture-13.md/50.png)

	- 노란박스가 실제 이미지
	- 진짜 같은 이미지를, 단순 복제가 아니라 잘 생성하는 것을 알 수 있음
	- DCGAN에서 CNN 아키텍처를 처음 적용해 현재 GAN의 성능이 엄청 올라감

		![51](/assets/img/2023-06-01-CS231n---Lecture-13.md/51.png)


		![52](/assets/img/2023-06-01-CS231n---Lecture-13.md/52.png)


		→ 굉장히 고퀄리티


		![53](/assets/img/2023-06-01-CS231n---Lecture-13.md/53.png)


		→ interpolate시 부드럽게 이미지가 변함을 볼 수 있음

	- 잠재 변수 z를 가지고 연산

		![54](/assets/img/2023-06-01-CS231n---Lecture-13.md/54.png)


		→ semantic한 의미가 잘 표현됨을 알 수 있음

- **Other models**

	![55](/assets/img/2023-06-01-CS231n---Lecture-13.md/55.png)

- **Summary**

	![56](/assets/img/2023-06-01-CS231n---Lecture-13.md/56.png)

	- 성능 굉장히 좋다
	- 하지만 까다롭고 불안정하며, 직접 최적화가 아님
	- VAE 처럼 P(x)나 P(z|x) 등을 구할 수 없다.
