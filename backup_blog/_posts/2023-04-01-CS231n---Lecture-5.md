---
layout: single
date: 2023-04-01
title: "CS231n - Lecture 5"
use_math: true
author_profile: false
tags: [강의/책 정리, ]
categories: [AI, ]
---

![0](/assets/img/2023-04-01-CS231n---Lecture-5.md/0.png)_답: 7x7 ( (9-3)+1 )_



## Lecture 5. Convolutional Neural Networks

- 1957년 최초로 perceptron을 구현되었고, 여기서 가중치 W를 업데이트하는 update rule가 나타났다
- 1960년에 Multilayer Perceptron Network인 Adaline/Madaline이 발명되었다
- 1986년 처음으로 backpropagation이 나타났고, 신경망의 학습이 시작되었다. 그러나 여러 가지 상황에 의해 다시 암흑기에 들어갔다
- 2006년 Deep Learning의 학습 가능성이 나타났다. 초기화에는 RBM이 이용되었고 hidden Layer에서 가중치가 학습되었다. 그 후 전체 신경망을 backpropagation을 하거나 fine-tuning하는 식으로 진행되었다
- 신경망의 광풍은 2012년부터 시작되었다. ImageNet 분류를 통해 에러를 극적으로 감소시키는 AlexNet가 landmark paper로 나타났다. 이 때부터 CNN이 널리 사용되기 시작했다
- 고양이의 뇌에 신호로 자극을 주었을 때, 고양이가 edges와 shapes에 반응을 보인다는 것을 알게 되었다
- 뇌의 특정 뉴런은 특정 방향에 반응한다는 것을 발견했다
- 뉴런이 계층구조를 가진다는 것을 알아냈다
- 생물학적 성과를 컴퓨터로 simulation한 것이 Neocognitron이다. simple cell과 complex cell을 반복적으로 쌓아가는 '샌드위치' 구조를 가지고 있다. 그러나 backpropagation은 하지 못했다
- 1998년 Backpropagation이 가능한 gradient-based learning이 글자 인식에 적용되었다. 이는 우편번호의 숫자를 인식하는 용도로 사용되었다


### Fully Connected Layer


![1](/assets/img/2023-04-01-CS231n---Lecture-5.md/1.png)

- Fully Connected Layer에서는 `Input Image`를 1차원으로 펴서 Weight 값과 곱해준다
- Weight의 크기는 `Input Image X Class Number` 이다
- **단점**
	- Input Image를 1차원으로 펴서 사용한다는 점에서 지역적 정보를 사용할 수 없다
	- Class Number가 많아지게 되면 Overfitting 문제가 발생하기 쉽다
- Fully Connected Layer는 `지역적 연결성(local connectivity)`와 `Weight 수에 따른 overfitting` 문제가 있다


### Convolutional Neural Networks


![2](/assets/img/2023-04-01-CS231n---Lecture-5.md/2.png)

- CNN에서 이미지의 크기는 `Width x Height x Channel` 순서로 부르고, Weight를 `Filter`라고 부른다
- Filter의 한 변의 크기는 Image의 `Width X Height`의 크기보다는 작은 값을 가지고, **Depth 크기는 반드시 입력 Channel의 갯수와 같다**. → **무조건 정방행렬이 아니어도 되는가?**
- 왼쪽 위 모서리부터 필터가 Image를 슬라이딩하면서 Filter가 씌어진 부분을 `dot product` 한다
- Filter가 씌어진 부분끼리 각각 곱한 뒤에 모두 더한 값에 Bias을 더한 값을 출력 값으로 사용한다
- Image를 Filter로 쭉 슬라이딩하면 Image가 가지는 특징을 나타내주는 1개의 `Activation Map`이 생성된다

![3](/assets/img/2023-04-01-CS231n---Lecture-5.md/3.png)


![4](/assets/img/2023-04-01-CS231n---Lecture-5.md/4.png)


![5](/assets/img/2023-04-01-CS231n---Lecture-5.md/5.png)

- 6개의 Filter를 사용하면 6개에 각각의 activation map을 형성하고, 이것을 쌓아서 Depth의 크기가 6인 `Activation Map` 을 얻는다
- Input Image의 Depth를 `D`, Filter의 한 변의 길이를 `F`, Bias를 `B`, Filter의 개수를 `N`라고 하면 파라미터의 개수는 `(F * F * D + 1) * N` 이다.
- 이렇게 만들어진 Output은 다음 Layer의 Input이 된다.

![6](/assets/img/2023-04-01-CS231n---Lecture-5.md/6.png)

- Convolutional Layer는 처음에는 간단한 특징인 Low-Level을 얻어내고, Layer가 깊어지면 깊어질수록 더욱 더 복잡하고, 정교한 특징을 얻어낸다

![7](/assets/img/2023-04-01-CS231n---Lecture-5.md/7.png)

- 각 `Filter`마다 위와 같은 `Activation Map`이 생기고, 이는 사진의 어떠한 부분의 특징을 나타낸다
- 주황색 박스 쳐져있는 Filter와 Activation Map을 보면, Filter는 Edge를 가리키고 있고, Activation Map은 Edge 부분을 강조하며 나타내고 있다
- 파란색 박스 쳐져있는 Filter와 Activation Map을 보면, Filter는 사진의 주황색 부분을 가리키고 있고, Activation Map은 차의 백라이트 부분을 강조하며 나타내고 있다

![8](/assets/img/2023-04-01-CS231n---Lecture-5.md/8.png)

- `Input Image`는 `Conv Layer`을 통과한 후에는 `Non-Linear-Layer`을 통과한다
- Non-Linear-Layer는 `RELU`를 가장 많이 사용한다
- Conv, RELU, Conv, RELU를 통과하고 나면, Activation Map의 크기를 늘려주는 `Pooling Layer`를 통과한다
- CNN의 끝단에는 최종 스코어를 계산하기 위해 `Fully Connected Layer`를 통과하게 된다


#### **Convolutional Layer Stride**


![9](/assets/img/2023-04-01-CS231n---Lecture-5.md/9.png)

- Stride는 Filter가 이미지를 슬라이딩할 때 움직이는 `Step의 크기`를 말한다
- Input Image의 한 변의 길이를 `W`, Filter의 한 변의 길이를 `F`, Stride를 `S`라고 하면 Activation Map의 한 변의 길이는 `(W - F) / S + 1` 이다


#### **Convolutional Layer Pad**


![10](/assets/img/2023-04-01-CS231n---Lecture-5.md/10.png)

- Convolutional Layer는 Filter의 크기에 따라서 출력의 Width X Height의 크기가 줄어드는 것을 볼 수 있다
- Pad는 `원본 Image의 크기를 유지`하며, `이미지의 가장자리가 덜 계산되는 것을 방지`한다
- Pad의 종류에는 Zero, Mirror, Extend 등의 방법이 있다
- Filter의 한 변의 길이를 `F` 라고 하면, Padding의 크기는 `(F - 1) / 2`로 하면 원본 Image의 크기를 유지할 수 있다
- Input Image의 한 변의 길이를 `W`, Filter의 한 변의 길이를 `F`, Stride를 `S`, Pad를 `P`라고 하면 Activation Map의 한 변의 길이는 `(W + 2 * P - F) / S + 1` 이다


#### **Convolutional Layer Output(Activation Map) Size**

- `W1`  : Input Image Width
- `H1`  : Input Image Height
- `D1`  : Input Image Depth
- `K` : Filter Number
- `F` : Filter Width
- `S` : Stride
- `P` : Padding
- `Output W2` : `(W1 - F + 2 * P) / S + 1`
- `Output H2` : `(H1 - F + 2 * P) / S + 1`
- `Output D2` : `K`
- `Parameter Number` : `(F * F * D1) * K + K`

![11](/assets/img/2023-04-01-CS231n---Lecture-5.md/11.png)



### Convolution Layer 특징


![12](/assets/img/2023-04-01-CS231n---Lecture-5.md/12.png)

- `지역적 연결성(local Connectivity)`
	- Fully Connected Layer와 다르게 입력 값에 주변의 로컬한 영역에 연결한다는 장점이 있습니다.
	- 깊이에 대해서는 전체를 다 봅니다.
	- **Receptive Field** : 한 뉴런이 한 번에 수용할 수 있는 영역을 의미
- `공간적 배치(Spatial arrangement)`
	- 출력의 크기는 4개의 하이퍼파라미터로부터 결정됩니다.
	- 앞에서 살펴본 Filter의 사이즈(F), Stride(S), zero-padding(P), filter의 개수(K)입니다.
	- 아래의 예시를 봅시다.
	- 이 예제는 가로/세로 공간적 차원중 하나만 고려했습니다 (x축).
	- 첫번째 예시는 `W=5, F=3, S=1, P=1`인 경우입니다.
	- 두번째 예시는 `W=5, F=3, S=2, P=1`인 경우입니다.
	- 위 두 예시와 같이 파라미터에 따라서 출력의 크기가 정해집니다.
- `모수 공유(Parameter Sharing)`
	- 각 채널에 대해서 하나의 filter를 사용하여 parameter를 공유한다는 이야기입니다.
	- 이러한 점은 parameter의 수를 줄일 수 있습니다.


#### Convolution Layer의 Backpropagation

- Backpropagation 과정에서 각 depth slice 내의 모든 뉴런들이 가중치에 대한 gradient를 계산하겠지만, 가중치 업데이트를 할 때에는 이 gradient들을 합해 사용한


### Pooling Layer


![13](/assets/img/2023-04-01-CS231n---Lecture-5.md/13.png)

- Pooling은 Activation Map의 크기를 Down Sampling 하는 과정으로 이미지의 크기를 줄이는 것이다
- Convolutional Layer의 깊이가 깊어지면 많은 계산 양을 요구한다
- 이때 Pooling 기법을 이용해서 이미지의 크기를 줄여서 속도를 높이고자 한다
- 이미지를 줄이는 방법은 위에서 Convolutional layer의 Stride를 이용해서도 줄일 수 있다
- Pooling 기법이 계산량과 weight의 수 측면에서 더 좋습니다.


#### Max Pooling Layer


![14](/assets/img/2023-04-01-CS231n---Lecture-5.md/14.png)

- Max Pooling은 Pooling의 가장 대표적인 방법
- 4 x 4 입력 이미지를 2 x 2 Filter로, Stride는 2로 Pooling 한다. Filter에 Convolution 하듯이 Max 연산을 해주면 해상도를 2배로 줄일때 가장 잘보이는 성분을 남기는 것과 같다
- 일반적으로 Stride를 설정할때는 Filter끼리 서로 겹치는 것을 지양한다
- Max Pooling을 사람의 뉴런 관점에서 생각할때, 가장 큰 신호만 전파시키는 방식이


#### **Pooling Size**

- `W1`  : Input Image Width
- `H1`  : Input Image Height
- `D1`  : Input Image Depth
- `F` : Spatial Extent
- `S` : Stride
- `Output W2` : `(W1 - F) / S + 1`
- `Output H2` : `(H1 - F) / S + 1`
- `Output D2` : `K`

![15](/assets/img/2023-04-01-CS231n---Lecture-5.md/15.png)



#### Max Pooling Layer Backpropagation

- Backpropagation에서 $max(x, y)$의 backward pass는 그냥 forward pass에서 가장 큰 값을 가졌던 입력의 gradient를 보내는 것과 같다
- 따라서 forward pass 과정에서 보통 max 액티베이션의 위치를 저장해두었다가 backpropagation 때 사용한다


### Summary

- CNN은 CONV, POOL, FC layer들을 쌓아 올린 형태의 Network이다
- 요즘 트렌드는 Filter를 자그마하게 만들고, 더욱 깊은 아키텍처를 만드는 것이고, POOL과 FC layer를 빼서 그냥 CONV만 하게 만들기도 한다
- 일반적인 아키텍처(전체적인 구조)는 일반적으로, CONV-RELU 여러 번 한 다음 POOL 하는 것을 몇 번 반복해 주고, 마지막에 FC와 ReLU 몇 번 한 다음 SOFTMAX로 loss를 찾는다
- ResNet / GoogLeNet 같은 경우에는 이런 패러다임을 따르지 않았다
